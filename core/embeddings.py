import os
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings


def init_vector_store():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    persist_dir = "chroma_db"
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # –ï—Å–ª–∏ –±–∞–∑–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –∑–∞–≥—Ä—É–∂–∞–µ–º
    if os.path.exists(persist_dir) and os.listdir(persist_dir):
        print("‚ôªÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã")
        return Chroma(
            persist_directory=persist_dir,
            embedding_function=embeddings
        ).as_retriever(search_kwargs={"k": 3})

    print("üÜï –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    loader = DirectoryLoader(
        "knowledge_base/",
        glob="**/*.txt",
        loader_cls=TextLoader,
        show_progress=True,
        use_multithreading=True
    )
    docs = loader.load()

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        length_function=len
    )
    chunks = splitter.split_documents(docs)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã
    vectordb = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=persist_dir
    )
    vectordb.persist()
    return vectordb.as_retriever(search_kwargs={"k": 3})